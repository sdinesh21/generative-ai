{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Gemini 2.0 Flash Model - Basic Response\n",
    "\n",
    "This notebook demonstrates how to use Google's python-genai SDK to interact with the Gemini 2.0 Flash model. The Flash model is optimized for quick responses and is ideal for real-time applications.\n",
    "\n",
    "## Prerequisites\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "A Gemini API key:\n",
    "   - Go to [Google AI Studio](https://aistudio.google.com)\n",
    "   - Click on 'Get API key' in the top right\n",
    "   - Create a new API key or use an existing one\n",
    "   - Copy the API key for use in step 2\n",
    "\n",
    "## What You'll Learn\n",
    "- How to install and import the Google Generative AI SDK\n",
    "- How to initialize and configure the Gemini model\n",
    "- How to generate responses from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages\n",
    "First, we'll install the necessary packages:\n",
    "- `google-genai`: The official Google Generative AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-genai) (2.38.0)\n",
      "Requirement already satisfied: pydantic<3.0.0dev,>=2.0.0 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-genai) (2.11.0a2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.28.1 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: websockets<15.0dev,>=13.0 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-genai) (14.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0dev,>=4.11.0 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-genai) (4.12.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai) (4.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from pydantic<3.0.0dev,>=2.0.0->google-genai) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from requests<3.0.0dev,>=2.28.1->google-genai) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/dineshselvaraj/Github/generative-ai/.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Dependencies and Configure API Key\n",
    "\n",
    "Now we'll:\n",
    "1. Import the required modules\n",
    "2. Configure the SDK with API key\n",
    "\n",
    "```\n",
    "GEMINI_API_KEY=your_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "# Configure the API key\n",
    "GEMINI_API_KEY = '<YOUR_API_KEY>'\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"Please set the GEMINI_API_KEY\")\n",
    "\n",
    "# Initialize the SDK\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Model and Generate Response\n",
    "\n",
    "Now we'll:\n",
    "1. Initialize the Gemini 2.0 Flash model\n",
    "2. Create a prompt\n",
    "3. Generate and display the response\n",
    "\n",
    "The Gemini 2.0 Flash model is designed for:\n",
    "- Quick responses\n",
    "- General text generation\n",
    "- Question answering\n",
    "- Summarization\n",
    "\n",
    "You can modify the prompt to ask different questions or perform different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "Okay, let's break down the key differences between traditional machine learning and deep learning.  They're both subfields of artificial intelligence, but they approach problem-solving in fundamentally different ways.\n",
      "\n",
      "**Traditional Machine Learning**\n",
      "\n",
      "*   **Feature Engineering is Crucial:** This is the biggest hallmark.  In traditional ML, you, the data scientist or engineer, are largely responsible for identifying and extracting relevant features from the raw data.  This requires domain expertise and careful experimentation. You need to understand what aspects of the data are important for the model to learn.\n",
      "\n",
      "    *   **Example:** If you're building a spam filter, you might manually calculate features like the frequency of certain words (e.g., \"viagra,\" \"free\"), the presence of excessive exclamation points, the sender's domain reputation, etc.  These hand-crafted features are then fed into the ML algorithm.\n",
      "*   **Algorithms:** Employs a wide range of algorithms, each well-suited for different types of tasks and data:\n",
      "    *   **Linear Regression:** For predicting continuous values.\n",
      "    *   **Logistic Regression:** For binary classification (e.g., spam/not spam).\n",
      "    *   **Support Vector Machines (SVMs):** Effective for classification tasks, especially when data is high-dimensional.\n",
      "    *   **Decision Trees:** Tree-like structures that make decisions based on feature values.\n",
      "    *   **Random Forests:** Ensembles of decision trees, improving accuracy and robustness.\n",
      "    *   **Naive Bayes:** Based on Bayes' theorem, often used for text classification.\n",
      "    *   **K-Nearest Neighbors (KNN):** Classifies data points based on the majority class of their nearest neighbors.\n",
      "*   **Limited Scalability (with Data):** Performance often plateaus after a certain amount of data is added.  Since the features are fixed, the model can only learn so much with more examples.  More data might not lead to significant improvements without re-engineering the features.\n",
      "*   **Simpler Models:** Models are generally less complex, requiring less computational power to train and run. This also means they are often easier to interpret and debug.\n",
      "*   **Explainability:** Often more explainable. You can usually understand why a traditional ML model made a particular prediction by looking at the feature weights or the structure of the decision tree.\n",
      "*   **Suitable for Smaller Datasets:** Can perform well even with relatively small datasets, especially when feature engineering is done effectively.\n",
      "\n",
      "**Deep Learning**\n",
      "\n",
      "*   **Automatic Feature Extraction:** This is the core advantage.  Deep learning models (specifically, neural networks) learn features directly from raw data.  You don't need to manually engineer features.  The network automatically discovers hierarchical representations of the data.\n",
      "\n",
      "    *   **Example:** In image recognition, a deep learning model might automatically learn to detect edges, corners, textures, and then combine these into higher-level features like eyes, noses, and faces, without any explicit instructions.\n",
      "*   **Neural Networks:** Primarily based on artificial neural networks with multiple layers (hence \"deep\").  Common architectures include:\n",
      "    *   **Convolutional Neural Networks (CNNs):** Excellent for image and video processing.\n",
      "    *   **Recurrent Neural Networks (RNNs):** Designed for sequential data like text and time series.  Variants like LSTMs and GRUs address the vanishing gradient problem.\n",
      "    *   **Transformers:**  A more recent architecture that excels in natural language processing, using self-attention mechanisms.\n",
      "    *   **Autoencoders:** Used for dimensionality reduction and anomaly detection.\n",
      "    *   **Generative Adversarial Networks (GANs):** Used for generating new data that resembles the training data.\n",
      "*   **Scalability (with Data):** Performance typically improves significantly with larger datasets.  Deep learning models have the capacity to learn more complex patterns from vast amounts of data.  More data almost always helps.\n",
      "*   **Complex Models:** More complex models with many parameters, requiring significant computational resources (GPUs or TPUs) for training.\n",
      "*   **Black Box:** Often considered a \"black box\" because it can be difficult to understand exactly how the model arrives at its predictions.  Explainability is a major research area in deep learning.\n",
      "*   **Requires Large Datasets:** Generally requires very large datasets to train effectively and avoid overfitting.\n",
      "*   **End-to-End Learning:**  Can learn directly from raw data to the final output, without intermediate steps that require human intervention.\n",
      "\n",
      "**Here's a table summarizing the key differences:**\n",
      "\n",
      "| Feature             | Traditional Machine Learning | Deep Learning                       |\n",
      "| ------------------- | ----------------------------- | ----------------------------------- |\n",
      "| **Feature Engineering** | Manual, Crucial               | Automatic, Learns from data           |\n",
      "| **Algorithms**         | Variety of algorithms         | Neural Networks (CNNs, RNNs, etc.) |\n",
      "| **Data Requirements**   | Smaller datasets often sufficient | Large datasets essential             |\n",
      "| **Scalability**       | Performance plateaus          | Performance improves with data      |\n",
      "| **Complexity**        | Simpler models                | More complex models                 |\n",
      "| **Computational Resources** | Lower                         | Higher (GPUs/TPUs)                  |\n",
      "| **Explainability**    | More explainable              | Often a \"black box\"                 |\n",
      "| **End-to-End Learning** | Less common                   | More common                         |\n",
      "\n",
      "**When to Use Which?**\n",
      "\n",
      "*   **Traditional ML:**\n",
      "    *   When you have a limited amount of data.\n",
      "    *   When you have strong domain knowledge and can manually engineer relevant features.\n",
      "    *   When you need a model that is easily interpretable and explainable.\n",
      "    *   When computational resources are limited.\n",
      "*   **Deep Learning:**\n",
      "    *   When you have a very large dataset.\n",
      "    *   When you don't have strong domain knowledge or want the model to automatically discover features.\n",
      "    *   When you need state-of-the-art performance, even if it comes at the cost of explainability.\n",
      "    *   When you have access to sufficient computational resources (GPUs/TPUs).\n",
      "    *   When dealing with complex data like images, audio, or text.\n",
      "\n",
      "**In a Nutshell:**\n",
      "\n",
      "Traditional machine learning relies on human-engineered features and simpler algorithms. Deep learning learns features automatically from raw data using complex neural networks.  The choice between the two depends largely on the size of your dataset, your domain expertise, the need for explainability, and your available computational resources.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model_name = 'gemini-2.0-flash'\n",
    "\n",
    "# Example prompt - feel free to modify this!\n",
    "prompt = \"What are the key differences between traditional machine learning and deep learning?\"\n",
    "\n",
    "# Generate response\n",
    "response = client.models.generate_content(\n",
    "    model=model_name, contents=prompt\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"Model Response:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!\n",
    "\n",
    "Try these examples that work well with streaming:\n",
    "\n",
    "1. Long-form content:\n",
    "```python\n",
    "prompt = \"Write a detailed story about a space exploration mission\"\n",
    "```\n",
    "\n",
    "2. Step-by-step explanations:\n",
    "```python\n",
    "prompt = \"Explain how to build a web application from scratch, including all major steps\"\n",
    "```\n",
    "\n",
    "3. Creative writing:\n",
    "```python\n",
    "prompt = \"Write a poem about artificial intelligence, with at least 4 verses\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
